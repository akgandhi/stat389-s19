---
title: "Lab 17"
author: ""
output: html_document
---

# Set-up

Read in the following libraries and to load the metadata about
the MNIST dataset:

```{r}
library(readr)
library(dplyr)
library(glmnet)
library(keras)

mnist <- read_csv("https://statsmaths.github.io/ml_data/mnist_10.csv")
```

To get the actual data for the images, you'll have to download the mnist file
from here:

- https://drive.google.com/drive/folders/14k9wNUTUEB3hAjXS8wfXty5_uACu3ZXq

Once this is downloaded, you'll have to run something like this:

```{r}
x28 <- read_rds("../notes/image_data/mnist_10_x28.rds")
```

If you have trouble with any of this, please let me know as soon as possible.


# Todays lab

The only thing you need to do today is to play around with different models
and see how well they work. Once you are satisfied, pick the best model and
incorporate the predictions into your output in the final chunk below. Note:
I would suggest keeping each model in its own code chunk for readability.
Also, save your work frequently as it is quite likely that you will crash
R at some point.

I tried to put together a simple, minimally working solution here for you to
use as a reference point. Construct the dataset:

```{r}
X <- t(apply(x28, 1, cbind))
y <- mnist$class

X_train <- X[mnist$train_id == "train",]
y_train <- to_categorical(y[mnist$train_id == "train"])
```

Then build, compile, and train the model:

```{r}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 128, input_shape = ncol(X_train)) %>%
  layer_activation(activation = "relu") %>%
  
  layer_dense(units = 128) %>%
  layer_activation(activation = "relu") %>%
  
  layer_dense(units = ncol(y_train)) %>%
  layer_activation(activation = "softmax")

model %>% compile(loss = 'categorical_crossentropy',
                  optimizer = optimizer_rmsprop(),
                  metrics = c('accuracy'))

history <- model %>%
  fit(X_train, y_train, epochs = 10, validation_split = 0.2)
plot(history)
```

Finally, run a prediction on the "real" validation set:

```{r}
y_pred <- predict_classes(model, X)
tapply(y == y_pred, mnist$train_id, mean)
```

It's a good idea to finish with a confusion matrix:

```{r}
table(y[mnist$train_id == "train"], y_pred[mnist$train_id == "train"])
```

Finally, when you have the model you like, set `pred` equal to `y_pred` and run the final
line of code.

```{r}
pred <- y_pred
```

# Submission

The code below assumes that you have added a prediction named
`pred` to every row of the dataset.

```{r}
submit <- select(mnist, obs_id, train_id)
submit <- mutate(submit, pred = pred)
write_csv(submit, "class17_submit.csv")
```

Now, upload the csv file to GitHub and you are done.
