\documentclass[11pt]{article}
\usepackage[top=1.5cm,bottom=2cm,left=2cm,right= 2cm]{geometry}
\geometry{letterpaper}                   % ... or a4paper or a5paper or ...
%\geometry{landscape}                % Activate for for rotated page geometry
\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{changepage}
\usepackage{lscape}
\usepackage{enumitem}
\usepackage{ulem}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\usepackage{xcolor}

\definecolor{oiB}{rgb}{.337,.608,.741}
\definecolor{oiR}{rgb}{.941,.318,.200}
\definecolor{oiG}{rgb}{.298,.447,.114}
\definecolor{oiY}{rgb}{.957,.863,0}

\definecolor{light}{rgb}{.337,.608,.741}
\definecolor{dark}{rgb}{.337,.608,.741}

\usepackage[colorlinks=false,pdfborder={0 0 0},urlcolor= dark,colorlinks=true,linkcolor=black]{hyperref}

\newcommand{\light}[1]{\textcolor{light}{\textbf{#1}}}
\newcommand{\dark}[1]{\textcolor{dark}{#1}}
\newcommand{\gray}[1]{\textcolor{gray}{#1}}

%\date{}                                           % Activate to display a given date or no date

%

\begin{document}

{\LARGE \textcolor{oiB}{Learning Objectives \hfill Exam 01}} \\

\begin{enumerate}
\renewcommand\labelenumi{\textcolor{light}{\textbf{LO \theenumi.}}}

\item Define and understand the role of \textbf{training data} and
\textbf{testing data} in statistical learning.

\item Utilize common \textbf{loss functions}, including mean squared error,
absolute error, and misclassification error. You should be able to evaluate
these by hand on small datasets and in R code from larger ones.

\item Apply the one-dimensional \textbf{best split} estimator by hand on small
datasets.

\item Understand the R code in the function \verb|casl_utils_best_split|.

\item Visualize simple linear regression from a scatter plot and understand
the interpretation of the coefficients.

\item Derive the simple linear regression ordinary least squares (OLS)
coefficients using calculus.

\item Apply the matrix format of the least squares estimator and understand
the notation for $y$, $X$, $\beta$, and $\widehat{\beta}$.

\item View a matrix as a linear transformation between $\mathbb{R}^n$ and
$\mathbb{R}^m$ and matrix multiplication as function composition.

\item Understand the matrix transpose and inverse, its notation, and rules
for applying these to matrix equations.

\item Derive the equations for the gradient of an inner product:
\begin{align*}
\nabla_\beta \left( a^t \beta \right) &= a
\end{align*}
And the gradient of a quadratic form:
\begin{align*}
\nabla_\beta \left( \beta^t A \beta \right) &= \frac{1}{2} A^t \beta.
\end{align*}

\item Derive the normal equations for the ordinary least squares estimator for
multivariate linear regression.

\item Apply the \verb|lm.fit| function to have R compute the ordinary least
squares solution directly.

\item Understand and apply the expectation and variance operators on vector
equations.

\item Derive formulae for the expected value and variance of $\beta$ under the
assumption that $y = Xb + \epsilon$ with $\mathbb{E}\epsilon = 0$ and
$\mathbb{V}ar(\epsilon) = \sigma^2 I_n$.

\end{enumerate}

\end{document}

