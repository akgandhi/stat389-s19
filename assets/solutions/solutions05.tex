%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[12pt,hidelinks]{article}

% 1. Load LaTeX packages
\usepackage{fontspec}
\usepackage{geometry}
\usepackage{lastpage}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{xunicode}
\usepackage{listings}
\usepackage{color}
\usepackage{amssymb}

% 2. Define page dimensions and spacing
\geometry{top=1in, bottom=1in, left=1in, right=2in, marginparsep=4pt,
          marginparwidth=1in}
\setlength{\parindent}{0pt}
\setlength{\parskip}{12pt}

% 3. Set header, footer, and bibliography
\renewcommand{\headrulewidth}{0pt}
\pagestyle{fancyplain}
\fancyhf{}
\lfoot{}
\rfoot{page \thepage\ of \pageref{LastPage}}
\bibliographystyle{acm}

% 4. Set fonts for the document
\defaultfontfeatures{Mapping=tex-text}
\setromanfont{YaleNew}

% 5. Define custom code for book environments and commands
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\pkg}[1]{\textbf{#1}}

% 6. Define custom code for book environments and commands
\definecolor{verbgray}{gray}{0.9}
\definecolor{verbgray2}{gray}{0.975}

\lstnewenvironment{rcode}{%
  \lstset{backgroundcolor=\color{verbgray},
  frame=single,
  framerule=0pt,
  basicstyle=\ttfamily,
  keepspaces=true,
  columns=fullflexible}}{}

\lstnewenvironment{rres}{%
  \lstset{backgroundcolor=\color{verbgray2},
  frame=single,
  framerule=0pt,
  basicstyle=\ttfamily,
  keepspaces=true,
  columns=fullflexible}}{}

% 7. Define numbering scheme for equations (only needed for handout).
\numberwithin{equation}{section}
\setcounter{section}{5}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

{\LARGE Lab Solutions 05}

\vspace*{12pt}

\textbf{1. Assume that $Z$ is a random variable that only takes values between $0$
and $5$. Any value in this range is equally likely to occur. Write down the
formula for the density function $f$ that corresponds to this random variable.}

\vspace*{12pt}

The function $f$ should be constant between $0$ and $5$ and zero elsewhere. We
know that the total integral has to be $1$, so the height of the function must
be $1/5$. This gives:
\begin{align}
f(z) &= \begin{cases} 0, & z < 0 \\ 1/5, & z \in [0, 5] \\ 0, & z > 5 \end{cases}
\end{align}
Some students may worry about the edges and equality signs at the points $0$
and $5$. In truth, it doesn't matter and is not important because the density
function only has a meaning when integrated. Its value at a particular point
is not even well-defined in terms of the probability function.

\vspace*{12pt}


\textbf{2. Without doing any calculations, what do you expect to be the expected
value of $Z$ in the previous question?}

\vspace*{12pt}

The random variable is equally likely to be between $0$ and $5$, so it seems
reasonable that the expected value is right in the middle at $2.5$.

\vspace*{12pt}



\textbf{3. Using the formulae in the notes, show that your guess matches the mathematical
definition of $\mathbb{E}Z$.}

\vspace*{12pt}

We can see this mathematically as follows:
\begin{align}
\mathbb{E} Z &= \int_{-\infty}^{+\infty} z \cdot f(z) dz \\
&= \int_{-\infty}^{0} z \cdot f(z) dz + \int_{0}^{5} z \cdot f(z)dz +
\int_{5}^{+\infty} z \cdot f(z)dz \\
&= 0 + \int_{0}^{5} \frac{1}{5} \cdot zdz + 0 \\
&= \frac{1}{5} \cdot \left[z^2 / 2 \right]_{z=0}^{z=5} \\
&= \frac{5^2}{2 \cdot 5} = 2.5.
\end{align}
Which matches our intuition.

\vspace*{12pt}

\textbf{4. Prove the equation given for $\mathbb{V}ar(AZ)$.}

\vspace*{12pt}

Using the definition of the variance we have:
\begin{align}
\mathbb{V}ar(A\epsilon) &= \mathbb{E} \left[ \left(A\epsilon - \mathbb{E} A\epsilon \right)
\cdot \left(A\epsilon - \mathbb{E} A\epsilon \right)^t \right] \\
 &= \mathbb{E} \left[ \left(A\epsilon - A\mathbb{E} \epsilon \right)
\cdot \left(A\epsilon - A\mathbb{E} \epsilon \right)^t \right] \\
 &= \mathbb{E} \left[ A \left(\epsilon - \mathbb{E} \epsilon \right)
\cdot \left(A \left(\epsilon - \mathbb{E} \epsilon\right) \right)^t \right] \\
 &= A \mathbb{E} \left[\left(\epsilon - \mathbb{E} \epsilon \right)
\cdot \left(\epsilon - \mathbb{E} \epsilon\right)^t A^t \right] \\
&= A \mathbb{E} \left[\left(\epsilon - \mathbb{E} \epsilon \right)
\cdot \left(\epsilon - \mathbb{E} \epsilon\right)^t \right] A^t \\
&= A  \mathbb{V}ar(\epsilon) A^t.
\end{align}
Notice that I needed to use the rule $(AB)^T = B^tA^t$ in the second to last
step.

\vspace*{12pt}

\textbf{5. Assume that we have a random variable $y$ defined in terms of a random
variable $\epsilon$ such that:}
\begin{align}
y &= X b + \epsilon.
\end{align}
\textbf{Further assume that the expected value of the $\epsilon$ term is the zero vector
(a vector with zeros in every component). Show that the expected value of the
ordinary least squares equation for the estimate $\beta$ is equal to $b$.
This means that $\beta$ is an \textit{unbiased} estimator of $b$.}

\vspace*{12pt}

Note that we can think of the quantity $(X^tX)^{-1} X^t$ as a single matrix.
This makes the computation fairly straightforward:
\begin{align}
\mathbb{E} \beta &= \mathbb{E}\left[(X^tX)^{-1} X^t y  \right] \\
&= \mathbb{E}\left[(X^tX)^{-1} X^t (Xb + \epsilon)  \right] \\
&= \mathbb{E}\left[(X^tX)^{-1} X^t Xb \right] + \mathbb{E}\left[(X^tX)^{-1} X^t \epsilon \right] \\
&= (X^tX)^{-1} (X^t X) b + (X^tX)^{-1} X^t \mathbb{E}\epsilon \\
&= b + 0 = b.
\end{align}

\vspace*{12pt}

\textbf{6. Using the same set-up as above, further assume that:}
\begin{align}
\mathbb{V}ar(\epsilon) &= \sigma^2 \cdot I_n.
\end{align}
\textbf{For some fixed value $\sigma^2 > 0$. Derive a formula for the variance
of the ordinary least squares estimate $\beta$.}

\vspace*{12pt}

Here we just use the variance rule for a sum:
\begin{align}
\mathbb{V}ar(y) &= \mathbb{V}ar(Xb + \epsilon) = \mathbb{V}ar(\epsilon) = \sigma^2 \cdot I_n.
\end{align}

\vspace*{12pt}

\textbf{7. Finally, derive a formula for the variance of the ordinary least
squares estimate $\beta$.}

\vspace*{12pt}

Once again, considering $(X^tX)^{-1} X^t$ as a single matrix, and using the
previous result, we have:
\begin{align}
\mathbb{V}ar(\beta) &= \mathbb{V}ar((X^t X)^{-1} X^t y) \\
&= (X^t X)^{-1} X^t \cdot \mathbb{V}ar(y) \cdot \left[(X^t X)^{-1} X^t \right]^2 \\
&= (X^t X)^{-1} X^t \cdot \sigma^2 \cdot I_n \cdot \left[(X^t X)^{-1} X^t \right]^2 \\
&= \sigma^2 \cdot (X^t X)^{-1} X^t X (X^t X)^{-1} \\
&= \sigma^2 \cdot (X^t X)^{-1} (X^t X) (X^t X)^{-1} \\
&= \sigma^2 \cdot (X^t X)^{-1}
\end{align}






\end{document}

